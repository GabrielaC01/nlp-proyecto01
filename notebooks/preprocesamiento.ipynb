{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7532ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de ejemplo\n",
    "corpus = [\n",
    "    \"hola mundo\",\n",
    "    \"cómo estás\",\n",
    "    \"el modelo autoregresivo predice tokens uno por uno\",\n",
    "    \"los transformers usan atención\",\n",
    "    \"la máscara causal evita ver el futuro\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5949daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear vocabulario de caracteres únicos\n",
    "caracteres = sorted(list(set(\"\".join(corpus))))\n",
    "vocab = {c: i + 1 for i, c in enumerate(caracteres)}  # 0 reservado para padding\n",
    "vocab[\"<pad>\"] = 0\n",
    "inv_vocab = {i: c for c, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb6939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para codificar y decodificar texto\n",
    "def texto_a_indices(texto):\n",
    "    return [vocab[c] for c in texto]\n",
    "\n",
    "def indices_a_texto(indices):\n",
    "    return \"\".join([inv_vocab[i] for i in indices if i != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6090f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hola mundo' → [8, 14, 11, 2, 1, 12, 19, 13, 4, 14]\n",
      "'cómo estás' → [3, 22, 12, 14, 1, 5, 17, 18, 21, 17]\n",
      "'el modelo autoregresivo predice tokens uno por uno' → [5, 11, 1, 12, 14, 4, 5, 11, 14, 1, 2, 19, 18, 14, 16, 5, 7, 16, 5, 17, 9, 20, 14, 1, 15, 16, 5, 4, 9, 3, 5, 1, 18, 14, 10, 5, 13, 17, 1, 19, 13, 14, 1, 15, 14, 16, 1, 19, 13, 14]\n",
      "'los transformers usan atención' → [11, 14, 17, 1, 18, 16, 2, 13, 17, 6, 14, 16, 12, 5, 16, 17, 1, 19, 17, 2, 13, 1, 2, 18, 5, 13, 3, 9, 22, 13]\n",
      "'la máscara causal evita ver el futuro' → [11, 2, 1, 12, 21, 17, 3, 2, 16, 2, 1, 3, 2, 19, 17, 2, 11, 1, 5, 20, 9, 18, 2, 1, 20, 5, 16, 1, 5, 11, 1, 6, 19, 18, 19, 16, 14]\n",
      "\n",
      "Vocabulario:\n",
      "{' ': 1, 'a': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'r': 16, 's': 17, 't': 18, 'u': 19, 'v': 20, 'á': 21, 'ó': 22, '<pad>': 0}\n"
     ]
    }
   ],
   "source": [
    "# Convertir el corpus a secuencias de índices\n",
    "secuencias = [texto_a_indices(frase) for frase in corpus]\n",
    "\n",
    "for frase, indices in zip(corpus, secuencias):\n",
    "    print(f\"'{frase}' → {indices}\")\n",
    "\n",
    "print(\"\\nVocabulario:\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf99d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar vocabulario y secuencias\n",
    "import json\n",
    "with open(\"vocab.json\", \"w\") as f:\n",
    "    json.dump(vocab, f)\n",
    "\n",
    "import pickle\n",
    "with open(\"secuencias.pkl\", \"wb\") as f:\n",
    "    pickle.dump(secuencias, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
