{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a96867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7795cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "from modelo_autoregresivo import ModeloAutoregresivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b24b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar vocabulario y datos\n",
    "with open(\"vocab.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab = json.load(f)\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "with open(\"secuencias.pkl\", \"rb\") as f:\n",
    "    secuencias = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e194cf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeloAutoregresivo(\n",
       "  (embedding): Embedding(23, 128)\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=128, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear modelo\n",
    "vocab_size = len(vocab)\n",
    "modelo = ModeloAutoregresivo(vocab_size)\n",
    "modelo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbd523d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir una secuencia corta para prueba\n",
    "entrada = secuencias[0][:5]  \n",
    "entrada_tensor = torch.tensor(entrada).unsqueeze(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db3fb960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia final: hola umpgápuuuu\n"
     ]
    }
   ],
   "source": [
    "# Generación greedy\n",
    "output = entrada_tensor.clone()\n",
    "num_tokens_a_generar = 10\n",
    "\n",
    "for _ in range(num_tokens_a_generar):\n",
    "    seq_len = output.size(1)\n",
    "    mask = modelo.generate_causal_mask(seq_len).to(output.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = modelo.embedding(output) * math.sqrt(modelo.d_model)\n",
    "        emb = modelo.pos_encoder(emb)\n",
    "        emb = emb.transpose(0, 1)  # (seq_len, batch, dim)\n",
    "\n",
    "        logits = modelo.transformer_decoder(emb, emb, tgt_mask=mask)\n",
    "        logits = modelo.fc_out(logits)\n",
    "\n",
    "    ultimo_logit = logits[-1, 0, :]  # último token de salida\n",
    "    siguiente_token = torch.argmax(F.softmax(ultimo_logit, dim=-1)).view(1, 1)\n",
    "    output = torch.cat([output, siguiente_token], dim=1)\n",
    "\n",
    "print(\"Secuencia final:\", \"\".join([inv_vocab[idx.item()] for idx in output[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13576bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada 1: hola umpgápuuuu\n",
      "Entrada 2: cómo cmámuámmmm\n",
      "Entrada 3: el mompaeaeaeae\n",
      "Entrada 4: los tkggggggggm\n",
      "Entrada 5: la mááááááááámk\n"
     ]
    }
   ],
   "source": [
    "# Generar texto a partir de cada secuencia del corpus\n",
    "for i, entrada in enumerate(secuencias):\n",
    "    entrada_tensor = torch.tensor(entrada[:5]).unsqueeze(0)  # (1, 5)\n",
    "    output = entrada_tensor.clone()\n",
    "\n",
    "    for _ in range(10):  # generar 10 tokens nuevos\n",
    "        mask = modelo.generate_causal_mask(output.size(1)).to(output.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = modelo.embedding(output) * math.sqrt(modelo.d_model)\n",
    "            emb = modelo.pos_encoder(emb).transpose(0, 1)\n",
    "            logits = modelo.transformer_decoder(emb, emb, tgt_mask=mask)\n",
    "            logits = modelo.fc_out(logits)\n",
    "\n",
    "        ultimo_logit = logits[-1, 0, :]\n",
    "        siguiente_token = torch.argmax(F.softmax(ultimo_logit, dim=-1), dim=-1)\n",
    "        siguiente_token = siguiente_token.unsqueeze(0).unsqueeze(0)  # (1, 1)\n",
    "        output = torch.cat([output, siguiente_token], dim=1)\n",
    "\n",
    "    texto_generado = \"\".join([inv_vocab[idx.item()] for idx in output[0]])\n",
    "    print(f\"Entrada {i+1}: {texto_generado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc25be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generacion import GeneradorTexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68d415c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado: la mááááááááámk\n"
     ]
    }
   ],
   "source": [
    "# Crear el generador\n",
    "generador = GeneradorTexto(modelo, inv_vocab)\n",
    "\n",
    "# Generar texto a partir de la entrada_tensor\n",
    "texto_generado = generador.generar_greedy(entrada_tensor, num_tokens=10)\n",
    "\n",
    "print(\"Texto generado:\", texto_generado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf125f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada 1: hola mundo\n",
      "Generado:   hola umpgápuuuu\n",
      "\n",
      "Entrada 2: cómo estás\n",
      "Generado:   cómo cmámuámmmm\n",
      "\n",
      "Entrada 3: el modelo autoregresivo predice tokens uno por uno\n",
      "Generado:   el mompaeaeaeae\n",
      "\n",
      "Entrada 4: los transformers usan atención\n",
      "Generado:   los tkggggggggm\n",
      "\n",
      "Entrada 5: la máscara causal evita ver el futuro\n",
      "Generado:   la mááááááááámk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, secuencia in enumerate(secuencias[:5]):  # Cambia el 5 por el número de pruebas que quieras\n",
    "    entrada = torch.tensor(secuencia[:5]).unsqueeze(0)  # solo los primeros tokens\n",
    "    texto_generado = generador.generar_greedy(entrada, num_tokens=10)\n",
    "    texto_original = \"\".join([inv_vocab[idx] for idx in secuencia])\n",
    "    print(f\"Entrada {i+1}: {texto_original}\")\n",
    "    print(f\"Generado:   {texto_generado}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
